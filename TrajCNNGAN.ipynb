{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrajCNNGAN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/mz-zarei/Trajectory_Analysis/blob/main/TrajCNNGAN.ipynb",
      "authorship_tag": "ABX9TyP7mC043HbZKK2KG99gkR2x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mz-zarei/Trajectory_Analysis/blob/main/TrajCNNGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries - Select Device**"
      ],
      "metadata": {
        "id": "5zoH4aKX5iv2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "56SrxyZ65gEW",
        "outputId": "dff977ef-fb31-4fae-cc37-dad8819e5610",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "from torch import optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BS_size = 50\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data**"
      ],
      "metadata": {
        "id": "QoMuB1Xi6zD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load preprocessed dataset\n",
        "preprocessed_data = np.load(\"/content/drive/MyDrive/Trajectory_Analysis/Interaction/preprocessed_data_rot_360.npy\")\n",
        "# Seperate trajectories to x(first 10 frames) and y(last 10 frames)\n",
        "x_data = preprocessed_data[:,:,:,:10]\n",
        "y_data = preprocessed_data[:,:2,:,10:]\n",
        "# Split train/validation/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "# Train data loader\n",
        "train_data = data_utils.TensorDataset(torch.Tensor(X_train).float(), torch.Tensor(y_train).float())\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BS_size, shuffle=True)\n",
        "# Test data loader\n",
        "test_data = data_utils.TensorDataset(torch.Tensor(X_test).float(), torch.Tensor(y_test).float())\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BS_size, shuffle=True)\n",
        "# Validation data loader\n",
        "val_data = data_utils.TensorDataset(torch.Tensor(X_val).float(), torch.Tensor(y_val).float())\n",
        "val_loader = data_utils.DataLoader(val_data, batch_size=BS_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Q38yo5p-6I3-"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Generator and Discriminator**"
      ],
      "metadata": {
        "id": "1f4TBjMGgeoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorModel(nn.Module):\n",
        "    def __init__(self, start_filter_num):\n",
        "        '''\n",
        "        Initializer function\n",
        "        args: Training arguments\n",
        "        infer: Training or test time (true if test time)\n",
        "        '''\n",
        "        super(GeneratorModel, self).__init__()\n",
        "        self.start_filter_num = start_filter_num \n",
        "\n",
        "        self.Vconv1 = self.v_conv_layer_set(4, self.start_filter_num)\n",
        "        self.Vconv2 = self.v_conv_layer_set(self.start_filter_num, self.start_filter_num*2)\n",
        "        self.Vconv3 = self.v_conv_layer_set(self.start_filter_num*2, self.start_filter_num*4)\n",
        "        self.Vconv4 = self.v_conv_layer_set(self.start_filter_num*4, self.start_filter_num*8)\n",
        "        self.Vconv5 = self.v_conv_layer_set(self.start_filter_num*8, self.start_filter_num*16)\n",
        "        self.Vconv6 = self.v_conv_layer_set(self.start_filter_num*16, self.start_filter_num*32)\n",
        "\n",
        "        self.Hconv1 = self.h_conv_layer_set(4, self.start_filter_num)\n",
        "        self.Hconv2 = self.h_conv_layer_set(self.start_filter_num, self.start_filter_num*2)\n",
        "        self.Hconv3 = self.h_conv_layer_set(self.start_filter_num*2, self.start_filter_num*4)\n",
        "        self.Hconv4 = self.h_conv_layer_set(self.start_filter_num*4, self.start_filter_num*8)\n",
        "        self.Hconv5 = self.h_conv_layer_set(self.start_filter_num*8, self.start_filter_num*16)\n",
        "        self.Hconv6 = self.h_conv_layer_set(self.start_filter_num*16, self.start_filter_num*32)\n",
        "\n",
        "        \n",
        "        \n",
        "        self.fc1 = nn.Linear(self.start_filter_num*32*2, 2)\n",
        "\n",
        "    def v_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(3, 1), padding=(1,0)),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.LeakyReLU()\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "    def h_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(1, 3), padding=(0,1)),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.LeakyReLU()\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "\n",
        "    def forward(self, z, x):\n",
        "        \"\"\"\n",
        "        z: uniform noise [0,1] with shape of (batch,1,36,10)\n",
        "        x: input with shape of (batch,3,36,10)\n",
        "        \"\"\"\n",
        "        input = torch.cat([z,x], 1)                # -> batch_size * (1+3=4) * 36 * 10\n",
        "\n",
        "        Voutput = self.Vconv1(input)        \n",
        "        Voutput = self.Vconv2(Voutput)  \n",
        "        Voutput = self.Vconv3(Voutput)  \n",
        "        Voutput = self.Vconv4(Voutput)  \n",
        "        Voutput = self.Vconv5(Voutput)  \n",
        "        Voutput = self.Vconv6(Voutput)  \n",
        "\n",
        "        Houtput = self.Hconv1(input)        \n",
        "        Houtput = self.Hconv2(Houtput)  \n",
        "        Houtput = self.Hconv3(Houtput)  \n",
        "        Houtput = self.Hconv4(Houtput) \n",
        "        Houtput = self.Hconv5(Houtput)  \n",
        "        Houtput = self.Hconv6(Houtput)  \n",
        "\n",
        "        output = torch.cat([Voutput,Houtput], 1)   # -> BS * C * H(36) * W(10)\n",
        "        output = torch.transpose(output,1,3)       # -> BS * W(10) * H(36) * C\n",
        "        output = F.leaky_relu(self.fc1(output))    # -> BS * W(10) * H(36) * 2 \n",
        "        output = torch.transpose(output,1,3)       # -> BS * 2 * H(36) * W(10) same as y_train[0].shape\n",
        "        return output.to(device)\n",
        "\n",
        "class DiscriminatorModel(nn.Module):\n",
        "    def __init__(self, start_filter_num, fc_layer_out_size):\n",
        "        super(DiscriminatorModel, self).__init__()\n",
        "                \n",
        "        self.start_filter_num = start_filter_num \n",
        "        self.fc_layer_out_size = fc_layer_out_size\n",
        "\n",
        "        self.Vconv1 = self.v_conv_layer_set(4, self.start_filter_num)\n",
        "        self.Vconv2 = self.v_conv_layer_set(self.start_filter_num, self.start_filter_num*2)\n",
        "        self.Vconv3 = self.v_conv_layer_set(self.start_filter_num*2, self.start_filter_num*4)\n",
        "        self.Vconv4 = self.v_conv_layer_set(self.start_filter_num*4, self.start_filter_num*8)\n",
        "        self.Vconv5 = self.v_conv_layer_set(self.start_filter_num*8, self.start_filter_num*16)\n",
        "        self.Vconv6 = self.v_conv_layer_set(self.start_filter_num*16, self.start_filter_num*32)\n",
        "\n",
        "        self.Hconv1 = self.h_conv_layer_set(4, self.start_filter_num)\n",
        "        self.Hconv2 = self.h_conv_layer_set(self.start_filter_num, self.start_filter_num*2)\n",
        "        self.Hconv3 = self.h_conv_layer_set(self.start_filter_num*2, self.start_filter_num*4)\n",
        "        self.Hconv4 = self.h_conv_layer_set(self.start_filter_num*4, self.start_filter_num*8)\n",
        "        self.Hconv5 = self.h_conv_layer_set(self.start_filter_num*8, self.start_filter_num*16)\n",
        "        self.Hconv6 = self.h_conv_layer_set(self.start_filter_num*16, self.start_filter_num*32)\n",
        "\n",
        "        \n",
        "        \n",
        "        self.fc1 = nn.Linear(self.start_filter_num*32*2, self.fc_layer_out_size)\n",
        "        self.fc2 = nn.Linear(self.fc_layer_out_size*36*10, 1)\n",
        "\n",
        "    def v_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(3, 1), padding=(1,0)),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.LeakyReLU()\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "    def h_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(1, 3), padding=(0,1)),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.LeakyReLU()\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "\n",
        "    def forward(self, z, x):\n",
        "        \"\"\"\n",
        "        z: uniform noise [0,1] with shape of (batch,1,36,10)\n",
        "        x: input with shape of (batch,3,36,10)\n",
        "        \"\"\"\n",
        "        input = torch.cat([z,x], 1)                # -> batch_size * (1+3=4) * 36 * 10\n",
        "\n",
        "        Voutput = self.Vconv1(input)        \n",
        "        Voutput = self.Vconv2(Voutput)  \n",
        "        Voutput = self.Vconv3(Voutput)  \n",
        "        Voutput = self.Vconv4(Voutput)  \n",
        "        Voutput = self.Vconv5(Voutput)  \n",
        "        Voutput = self.Vconv6(Voutput)  \n",
        "\n",
        "        Houtput = self.Hconv1(input)        \n",
        "        Houtput = self.Hconv2(Houtput)  \n",
        "        Houtput = self.Hconv3(Houtput)  \n",
        "        Houtput = self.Hconv4(Houtput) \n",
        "        Houtput = self.Hconv5(Houtput)  \n",
        "        Houtput = self.Hconv6(Houtput)  \n",
        "\n",
        "        output = torch.cat([Voutput,Houtput], 1)   # -> BS * (32x2xstart_filter_num) * H(36) * W(10)\n",
        "        output = torch.transpose(output,1,3)       # -> BS * W(10) * H(36) * (32x2xstart_filter_num)\n",
        "        output = F.leaky_relu(self.fc1(output))    # -> BS * W(10) * H(36) * fc_layer_out_size \n",
        "        output = torch.flatten(output)\n",
        "        output = torch.sigmoid(self.fc2(output))\n",
        "        return output.to(device)\n"
      ],
      "metadata": {
        "id": "4H_92lGk_hlh"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the output size for each model\n",
        "generator = GeneratorModel(16)\n",
        "x = torch.randn(1,3, 36, 10) # BS x C x H x W\n",
        "z = torch.randn(1,1, 36, 10)\n",
        "\n",
        "output = generator(z, x)\n",
        "print(\"G output shape: \", output.shape)\n",
        "G_total_params = sum(p.numel() for p in generator.parameters())\n",
        "print(\"G number of parameters: \", G_total_params)\n",
        "\n",
        "\n",
        "\n",
        "discriminator = DiscriminatorModel(16, 512)\n",
        "x = torch.randn(1,3, 36, 10)\n",
        "y = torch.randn(1,1, 36, 10)\n",
        "\n",
        "output = discriminator(y, x)\n",
        "print(\"D output shape: \",output.shape)\n",
        "D_total_params = sum(p.numel() for p in discriminator.parameters())\n",
        "print(\"G number of parameters: \", D_total_params)\n"
      ],
      "metadata": {
        "id": "EyIZtAW4_3h4",
        "outputId": "12d845fe-9c72-45e6-e672-70836e14ff29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G output shape:  torch.Size([1, 2, 36, 10])\n",
            "G number of parameters:  1056034\n",
            "D output shape:  torch.Size([1])\n",
            "G number of parameters:  1763105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train TC-GAN"
      ],
      "metadata": {
        "id": "mTvSnhTC2zQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "X3-lLzHEdWYS",
        "outputId": "0176095a-79a6-4da9-e5cd-60fc40bd62ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4746], device='cuda:0', grad_fn=<ToCopyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M1BbVMJBmwy9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}