{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrajCNNGAN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/mz-zarei/Trajectory_Analysis/blob/main/TrajCNNGAN.ipynb",
      "authorship_tag": "ABX9TyPdgOUyNUGD+t29pqzdOgfP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mz-zarei/Trajectory_Analysis/blob/main/TrajCNNGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries - Select Device**"
      ],
      "metadata": {
        "id": "5zoH4aKX5iv2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "56SrxyZ65gEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d44c8bc-c34f-4206-891a-cd103d4eba06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn as nn\n",
        "from torch import optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data**"
      ],
      "metadata": {
        "id": "QoMuB1Xi6zD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BS_size = 50\n",
        "\n",
        "# Load preprocessed dataset\n",
        "preprocessed_data = np.load(\"/content/drive/MyDrive/Trajectory_Analysis/Interaction/preprocessed_data_rot_360.npy\")\n",
        "# Seperate trajectories to x(first 10 frames) and y(last 10 frames)\n",
        "x_data = preprocessed_data[:,:,:,:10]\n",
        "y_data = preprocessed_data[:,:2,:,10:]\n",
        "# Split train/validation/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "# Train data loader\n",
        "train_data = data_utils.TensorDataset(torch.Tensor(X_train).float(), torch.Tensor(y_train).float())\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BS_size, shuffle=True)\n",
        "# Test data loader\n",
        "test_data = data_utils.TensorDataset(torch.Tensor(X_test).float(), torch.Tensor(y_test).float())\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BS_size, shuffle=True)\n",
        "# Validation data loader\n",
        "val_data = data_utils.TensorDataset(torch.Tensor(X_val).float(), torch.Tensor(y_val).float())\n",
        "val_loader = data_utils.DataLoader(val_data, batch_size=BS_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "Q38yo5p-6I3-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Generator and Discriminator**"
      ],
      "metadata": {
        "id": "1f4TBjMGgeoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorModel(nn.Module):\n",
        "    def __init__(self, start_filter_num=4):\n",
        "        '''\n",
        "        Initializer function\n",
        "        args: Training arguments\n",
        "        infer: Training or test time (true if test time)\n",
        "        '''\n",
        "        super(GeneratorModel, self).__init__()\n",
        "\n",
        "        self.start_filter_num = start_filter_num \n",
        "\n",
        "\n",
        "\n",
        "        self.Vconv1 = self.v_conv_layer_set(4, self.start_filter_num)\n",
        "        self.Vconv2 = self.v_conv_layer_set(self.start_filter_num, self.start_filter_num*2)\n",
        "        self.Vconv3 = self.v_conv_layer_set(self.start_filter_num*2, self.start_filter_num*4)\n",
        "        self.Vconv4 = self.v_conv_layer_set(self.start_filter_num*4, self.start_filter_num*8)\n",
        "        self.Vconv5 = self.v_conv_layer_set(self.start_filter_num*8, self.start_filter_num*16)\n",
        "        self.Vconv6 = nn.Conv2d(self.start_filter_num*16, self.start_filter_num*32, \n",
        "                                kernel_size=(3, 1), padding=(1,0), bias=False)\n",
        "\n",
        "        self.Hconv1 = self.h_conv_layer_set(4, self.start_filter_num)\n",
        "        self.Hconv2 = self.h_conv_layer_set(self.start_filter_num, self.start_filter_num*2)\n",
        "        self.Hconv3 = self.h_conv_layer_set(self.start_filter_num*2, self.start_filter_num*4)\n",
        "        self.Hconv4 = self.h_conv_layer_set(self.start_filter_num*4, self.start_filter_num*8)\n",
        "        self.Hconv5 = self.h_conv_layer_set(self.start_filter_num*8, self.start_filter_num*16)\n",
        "        self.Hconv6 = nn.Conv2d(self.start_filter_num*16, self.start_filter_num*32, \n",
        "                                kernel_size=(1, 3), padding=(0,1), bias=False) \n",
        " \n",
        "        \n",
        "        self.fc1 = nn.Linear(self.start_filter_num*32*2, 2)\n",
        "        self.Tanh = nn.Tanh()\n",
        "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "\n",
        "    def v_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(1, 3), padding=(0,1), bias=False),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "    def h_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(3, 1), padding=(1,0), bias=False),\n",
        "        nn.BatchNorm2d(out_c),\n",
        "        nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "    def forward(self, past_traj, z):\n",
        "        \"\"\"\n",
        "        z: uniform noise [0,1] with shape of (batch,1,36,10)\n",
        "        past_traj: past traj with shape of (batch,3,36,10)\n",
        "        \"\"\"\n",
        "        input = torch.cat([past_traj,z], 1) # -> batch_size * (1+3=4) * 36 * 10\n",
        "\n",
        "        Voutput = self.dropout(self.Vconv1(input))    \n",
        "        Voutput = self.Vconv2(Voutput)  \n",
        "        Voutput = self.Vconv3(Voutput)  \n",
        "        Voutput = self.Vconv4(Voutput)  \n",
        "        Voutput = self.Vconv5(Voutput)  \n",
        "        Voutput = self.dropout(self.Vconv6(Voutput))  \n",
        "\n",
        "        Houtput = self.dropout(self.Hconv1(input))       \n",
        "        Houtput = self.Hconv2(Houtput)  \n",
        "        Houtput = self.Hconv3(Houtput)  \n",
        "        Houtput = self.Hconv4(Houtput) \n",
        "        Houtput = self.Hconv5(Houtput)  \n",
        "        Houtput = self.dropout(self.Hconv6(Houtput)) \n",
        "\n",
        "        output = torch.cat([Voutput,Houtput], 1)   # -> BS * C * H(36) * W(10)\n",
        "        output = torch.transpose(output,1,3)       # -> BS * W(10) * H(36) * C\n",
        "        output = self.Tanh(self.fc1(output))       # -> BS * W(10) * H(36) * 2 \n",
        "        output = torch.transpose(output,1,3)       # -> BS * 2 * H(36) * W(10) same as y_train[0].shape\n",
        "        return output.to(device)\n",
        "\n",
        "class GeneratorModel(nn.Module):\n",
        "    \"\"\" G(x) \"\"\"\n",
        "    def __init__(self, embedding_size, input_size, output_size):   \n",
        "        '''\n",
        "        Initializer function\n",
        "        '''\n",
        "        super(GeneratorModel, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.input_size = input_size                                   # means the input sequence length\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.input_embedding_layer = nn.Linear(1, self.embedding_size) # assume embedding_size = 32\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = self.input_size, out_channels = 2*self.input_size, kernel_size = 3, padding = (0,2), dilation=2)\n",
        "        self.bn1 = nn.BatchNorm2d(2*self.input_size)                   # padding 1 to keep the same size\n",
        "        self.conv2 = nn.Conv2d(in_channels = 2*self.input_size, out_channels = 4*self.input_size, kernel_size = 3, padding = (0,2), dilation=2)\n",
        "        self.bn2 = nn.BatchNorm2d(4*self.input_size)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 4*self.input_size, out_channels = 6*self.input_size, kernel_size = 3, padding = (0,2), dilation=2)\n",
        "        self.bn3 = nn.BatchNorm2d(6*self.input_size)\n",
        "        self.conv4 = nn.Conv2d(in_channels = 6*self.input_size, out_channels = 8*self.input_size, kernel_size = 3, padding = (0,2), dilation=2)\n",
        "        self.bn4 = nn.BatchNorm2d(8*self.input_size)\n",
        "\n",
        "        self.interm_fc1 = nn.Linear(8*16*self.input_size, 8*self.input_size)\n",
        "        self.output_fc = nn.Linear(8*self.input_size, self.output_size)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        input: assume x is input_sequence from one example of (input_sequence, prediction_sequence) \n",
        "        x inital size: 1 x 3 x A x T       1 X 2A X T\n",
        "        1 is the batch_size, A is the # of agents in that one example, T is the input sequence length\n",
        "        assuming 32 for embedding size\n",
        "        \"\"\"\n",
        "        x = x.float()\n",
        "        x = torch.unsqueeze(x, 3)                       # (N, H, C, W) = 1 x 2A x T x 1          \n",
        "        x = F.leaky_relu(self.input_embedding_layer(x)) # (N, H, C, W) = 1 x 2A x T x 32         \n",
        "\n",
        "        x = torch.transpose(x, 1, 3)                    # (N, H, C, W) = 1 x 32 x T x 2A         \n",
        "        x = torch.transpose(x, 1, 2)                    # (N, H, C, W) = 1 x T x 32 x 2A         \n",
        "\n",
        "        x = self.conv1(x) \n",
        "        x = F.leaky_relu(self.bn1(x))  \n",
        "        x = self.conv2(x)\n",
        "        x = F.leaky_relu(self.bn2(x)) \n",
        "        x = self.conv3(x)\n",
        "        x = F.leaky_relu(self.bn3(x))\n",
        "        x = self.conv4(x)\n",
        "        x = F.leaky_relu(self.bn4(x))                   # (N, H, C, W) = 1 x 8T x 16 x 2A      \n",
        "\n",
        "        x = torch.cat(torch.split(x, 1, dim=1), 2)      # (N, H, C, W) = 1 X 1 X 8T*16 X 2A\n",
        "\n",
        "        x = torch.transpose(x, 2, 3)                    # (N, H, W, C) = 1 X 1 X 2A X 8T*16\n",
        "        x = torch.transpose(x, 1, 2)                    # (N, W, H, C) = 1 X 2A X 1 X 8T*16\n",
        "\n",
        "        x = self.interm_fc1(x)                          # (N, W, H, C) = 1 X 2A X 1 X 8T*8\n",
        " \n",
        "        x = self.output_fc(x)                           # (N, W, H, C) = 1 X 2A X 1 X T\n",
        "        return F.leaky_relu(x)\n",
        "\n",
        "\n",
        "class DiscriminatorModel(nn.Module):\n",
        "    def __init__(self, start_filter_num=4, fc_layer_out_size=128):\n",
        "        super(DiscriminatorModel, self).__init__()\n",
        "                \n",
        "\n",
        "        \n",
        "        self.fc_x = nn.Linear(3, 10)           # x shape: BS * 3 * 32 * 10\n",
        "        self.fc_y = nn.Linear(2, 10)           # y shape: BS * 2 * 32 * 10\n",
        "\n",
        "        self.Vconv1 = self.v_conv_layer_set(5, start_filter_num*64)\n",
        "        self.Vconv2 = self.v_conv_layer_set(start_filter_num*64, start_filter_num*32)\n",
        "        self.Vconv3 = self.v_conv_layer_set(start_filter_num*32, start_filter_num*16)\n",
        "        self.Vconv4 = self.v_conv_layer_set(start_filter_num*16, start_filter_num*8)\n",
        "        self.Vconv5 = self.v_conv_layer_set(start_filter_num*8, start_filter_num*4)\n",
        "        self.Vconv6 = nn.Conv2d(start_filter_num*4, start_filter_num*2, \n",
        "                                kernel_size=(3, 1), padding=(1,0), bias=False) \n",
        "\n",
        "        self.Hconv1 = self.h_conv_layer_set(5, self.start_filter_num*64)\n",
        "        self.Hconv2 = self.h_conv_layer_set(self.start_filter_num*64, self.start_filter_num*32)\n",
        "        self.Hconv3 = self.h_conv_layer_set(self.start_filter_num*32, self.start_filter_num*16)\n",
        "        self.Hconv4 = self.h_conv_layer_set(self.start_filter_num*16, self.start_filter_num*8)\n",
        "        self.Hconv5 = self.h_conv_layer_set(self.start_filter_num*8, self.start_filter_num*4)\n",
        "        self.Hconv6 = nn.Conv2d(self.start_filter_num*4, self.start_filter_num*2, \n",
        "                                kernel_size=(1, 3), padding=(0,1), bias=False) \n",
        "\n",
        "        \n",
        "        \n",
        "        self.fc1 = nn.Linear(self.start_filter_num*2*2, self.fc_layer_out_size)\n",
        "        self.fc2 = nn.Linear(self.fc_layer_out_size*36*10, 1)\n",
        "\n",
        "        self.lrelu = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        \n",
        "    def v_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(3, 1), padding=(1,0), bias=False),\n",
        "        #nn.BatchNorm2d(out_c),                # for regular GAN\n",
        "        nn.InstanceNorm2d(out_c, affine=True), # for WGAN\n",
        "        nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "    def h_conv_layer_set(self, in_c, out_c):\n",
        "        conv_layer = nn.Sequential(\n",
        "        nn.Conv2d(in_c, out_c, kernel_size=(1, 3), padding=(0,1), bias=False),\n",
        "        #nn.BatchNorm2d(out_c),                # for regular GAN\n",
        "        nn.InstanceNorm2d(out_c, affine=True), # for WGAN\n",
        "        nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        return conv_layer\n",
        "\n",
        "    def forward(self, past_traj, future_traj):\n",
        "        \"\"\"\n",
        "        past_traj: past traj with shape of (batch,3,36,10)\n",
        "        future_traj: future traj with shape of (batch,2,36,10)\n",
        "        \"\"\"\n",
        "        input = torch.cat([past_traj,future_traj], 1)                # -> batch_size * (2+3=5) * 36 * 10\n",
        "\n",
        "        Voutput = self.Vconv1(input)        \n",
        "        Voutput = self.Vconv2(Voutput)  \n",
        "        Voutput = self.Vconv3(Voutput)  \n",
        "        Voutput = self.Vconv4(Voutput)  \n",
        "        Voutput = self.Vconv5(Voutput)  \n",
        "        Voutput = self.Vconv6(Voutput)  \n",
        "\n",
        "        Houtput = self.Hconv1(input)        \n",
        "        Houtput = self.Hconv2(Houtput)  \n",
        "        Houtput = self.Hconv3(Houtput)  \n",
        "        Houtput = self.Hconv4(Houtput) \n",
        "        Houtput = self.Hconv5(Houtput)  \n",
        "        Houtput = self.Hconv6(Houtput)  \n",
        "\n",
        "        output = torch.cat([Voutput,Houtput], 1)   # -> BS * (32x2xstart_filter_num) * H(36) * W(10)\n",
        "        output = torch.transpose(output,1,3)       # -> BS * W(10) * H(36) * (32x2xstart_filter_num)\n",
        "        output = self.lrelu(self.fc1(output))      # -> BS * W(10) * H(36) * fc_layer_out_size \n",
        "        output = torch.flatten(output,start_dim=1)\n",
        "        # output = self.dropout(output)\n",
        "        output = self.fc2(output)\n",
        "        # output = torch.sigmoid(output) # comment this for WGAN\n",
        "        return output.to(device)\n",
        "\n",
        "class DiscriminatorModel_(nn.Module):\n",
        "    def __init__(self, start_filter_num=4, fc_layer_out_size=128):\n",
        "        super(DiscriminatorModel, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            # input: N x 5 x 32 x 10\n",
        "            nn.Conv2d(5, start_filter_num, kernel_size=4, stride=1, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # _block(in_channels, out_channels, kernel_size, stride, padding)\n",
        "            self._block(start_filter_num, start_filter_num * 2, 4, 2, 1),\n",
        "            self._block(start_filter_num * 2, start_filter_num * 4, 4, 2, 1),\n",
        "            self._block(start_filter_num * 4, start_filter_num * 8, 4, 2, 1),\n",
        "            # After all _block img output is 4x1 (Conv2d below makes into 1x1)\n",
        "            nn.Conv2d(start_filter_num * 8, 1, kernel_size=(4,1), stride=1, padding=0),\n",
        "        )\n",
        "    \n",
        "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels, out_channels, kernel_size, stride, padding, bias=False,\n",
        "            ),\n",
        "            nn.InstanceNorm2d(out_channels, affine=True),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, past_traj, future_traj):\n",
        "        input = torch.cat([past_traj,future_traj], 1) # -> batch_size * (2+3=5) * 36 * 10\n",
        "        input = self.disc(input)\n",
        "        input = input.squeeze()              \n",
        "        return input.unsqueeze(1)\n"
      ],
      "metadata": {
        "id": "4H_92lGk_hlh"
      },
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the output size for each model\n",
        "generator = GeneratorModel(start_filter_num=16)\n",
        "traj_past = torch.randn(50, 3, 36, 10) # BS x C x H x W\n",
        "z = torch.rand(50, 1, 36, 10)\n",
        "\n",
        "output = generator(traj_past, z)\n",
        "print(\"G output shape: \", output.shape)\n",
        "G_total_params = sum(p.numel() for p in generator.parameters())\n",
        "print(\"G number of parameters: \", G_total_params)\n",
        "\n",
        "\n",
        "discriminator = DiscriminatorModel(start_filter_num=8, fc_layer_out_size=16)\n",
        "past_traj = torch.randn(50,3, 36, 10)\n",
        "future_traj = torch.randn(50,2, 36, 10)\n",
        "\n",
        "output = discriminator(past_traj, future_traj)\n",
        "print(\"D output shape: \",output.shape)\n",
        "D_total_params = sum(p.numel() for p in discriminator.parameters())\n",
        "print(\"G number of parameters: \", D_total_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyIZtAW4_3h4",
        "outputId": "789285de-6df4-47a1-88e8-ca0fea23cf3f"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G output shape:  torch.Size([50, 2, 36, 10])\n",
            "G number of parameters:  1051970\n",
            "D output shape:  torch.Size([50, 1])\n",
            "G number of parameters:  1073169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.rand(50, 1, 32, 10)\n",
        "x = torch.rand(50, 2*3, 10, 32)\n",
        "x = torch.transpose(x, 2, 3)\n",
        "print(torch.cat([x,z], 1).shape)"
      ],
      "metadata": {
        "id": "cAO2xSClk2t9",
        "outputId": "046d3734-7d19-4aff-e20e-d6c0349afbf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50, 7, 32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train TC-GAN**"
      ],
      "metadata": {
        "id": "mTvSnhTC2zQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "\n",
        "def bce_loss(input, target):\n",
        "    \"\"\"\n",
        "    Numerically stable version of the binary cross-entropy loss function.\n",
        "    As per https://github.com/pytorch/pytorch/issues/751\n",
        "    See the TensorFlow docs for a derivation of this formula:\n",
        "    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
        "    Input:\n",
        "    - input: PyTorch Tensor of shape (N, ) giving scores.\n",
        "    - target: PyTorch Tensor of shape (N,) containing 0 and 1 giving targets.\n",
        "    Output:\n",
        "    - A PyTorch Tensor containing the mean BCE loss over the minibatch of\n",
        "      input data.\n",
        "    \"\"\"\n",
        "    neg_abs = -input.abs()\n",
        "    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "def g_loss(scores_fake, gen_traj, real_traj):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    - scores_fake: Tensor of shape (N,) containing scores for fake samples\n",
        "    Output:\n",
        "    - loss: Tensor of shape (,) giving GAN generator loss\n",
        "    \"\"\"\n",
        "    y_fake = torch.ones_like(scores_fake) * torch.Tensor(np.random.uniform(0, 0.3, size=scores_fake.shape)).to(device)\n",
        "    loss1 = bce_loss(scores_fake, y_fake)\n",
        "    mse_loss = nn.MSELoss()\n",
        "    loss2 = mse_loss(gen_traj, real_traj)\n",
        "    w = 0\n",
        "    loss = loss1 + w * loss2\n",
        "    return loss\n",
        "\n",
        "\n",
        "def d_loss(scores_real, scores_fake):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    - scores_real: Tensor of shape (N,) giving scores for real samples\n",
        "    - scores_fake: Tensor of shape (N,) giving scores for fake samples\n",
        "    Output:\n",
        "    - loss: Tensor of shape (,) giving GAN discriminator loss\n",
        "    \"\"\"\n",
        "    y_real = torch.ones_like(scores_real) * torch.Tensor(np.random.uniform(0.7, 1.2, size=scores_real.shape)).to(device)\n",
        "    y_fake = torch.ones_like(scores_fake) * torch.Tensor(np.random.uniform(0, 0.3, size=scores_fake.shape)).to(device)\n",
        "    loss_real = bce_loss(scores_real, y_real)\n",
        "    loss_fake = bce_loss(scores_fake, y_fake)\n",
        "    loss = loss_real + loss_real\n",
        "    return loss\n",
        "\n",
        "\n",
        "def optimizer(opt=\"rmsp\"):\n",
        "    if opt == \"rmsp\":\n",
        "        optimizerD = torch.optim.RMSprop(netD.parameters(), lr=D_lr)\n",
        "        optimizerG = torch.optim.RMSprop(netG.parameters(), lr=G_lr)\n",
        "    elif opt == \"adam\":\n",
        "        optimizerD = optim.Adam(netD.parameters(), lr=D_lr, betas=(beta1, 0.999), eps = D_lr/num_epochs)\n",
        "        optimizerG = optim.Adam(netG.parameters(), lr=G_lr, betas=(beta1, 0.999), eps = G_lr/num_epochs)\n",
        "    elif opt == \"sgd\":\n",
        "        optimizerD = optim.SGD(netD.parameters(), lr=D_lr, momentum=beta1, dampening=0, weight_decay=0, nesterov=True)\n",
        "        optimizerG = optim.SGD(netG.parameters(), lr=G_lr, momentum=beta1, dampening=0, weight_decay=0, nesterov=True)\n",
        "    else:\n",
        "        return \"Invalid optimizer type\"\n",
        "    return optimizerD, optimizerG\n",
        "\n",
        "\n",
        "def gradient_penalty(critic, condition, real, fake, device=\"cpu\"):\n",
        "    BATCH_SIZE, C, H, W = real.shape\n",
        "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
        "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
        "\n",
        "    # Calculate critic scores\n",
        "    mixed_scores = critic(condition, interpolated_images)\n",
        "\n",
        "    # Take the gradient of the scores with respect to the images\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=interpolated_images,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
        "    return gradient_penalty        \n",
        "\n",
        "\n",
        "def Train(generator, discriminator, mode=\"WGAN\"):\n",
        "    # Lists to keep track of progress\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    iters = 0\n",
        "\n",
        "    # Initialize BCELoss and MSELoss function\n",
        "    BCEloss = nn.BCELoss()\n",
        "    MSELoss = nn.MSELoss()\n",
        "\n",
        "    # Establish convention for real and fake labels during training\n",
        "    real_label = 1.\n",
        "    fake_label = 0.\n",
        "\n",
        "    # Training Loop\n",
        "    print(\"Starting Training Loop...\")\n",
        "    # For each epoch\n",
        "    for epoch in range(num_epochs):\n",
        "        # For each batch in the dataloader\n",
        "        for i, (real_past_traj, real_future_traj) in enumerate(train_loader):\n",
        "\n",
        "            ############################\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            ###########################\n",
        "            ## Train with all-real batch\n",
        "            netD.zero_grad()\n",
        "            # Format batch\n",
        "            real_past_traj = real_past_traj.to(device)\n",
        "            real_future_traj = real_future_traj.to(device)\n",
        "\n",
        "            b_size = real_past_traj.size(0)\n",
        "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "            # Forward pass real batch through D\n",
        "            scores_real = netD(real_past_traj, real_future_traj).view(-1)\n",
        "            # Calculate loss on all-real batch\n",
        "            errD_real =  BCEloss(scores_real, label)\n",
        "            # Calculate gradients for D in backward pass\n",
        "            errD_real.backward()\n",
        "            D_x = scores_real.mean().item()\n",
        "\n",
        "            ## Train with all-fake batch\n",
        "            # Generate batch of latent vectors\n",
        "            noise = torch.randn((real_past_traj.size(0),1,embedding_size,input_length), device=device)\n",
        "            # Generate future traj batch with G\n",
        "            fake = netG(real_past_traj, noise)\n",
        "            label.fill_(fake_label)\n",
        "            # Classify all fake batch (generated future traj) with D\n",
        "            scores_fake = netD(real_past_traj, fake.detach()).view(-1)\n",
        "            # Calculate D's loss on the all-fake batch\n",
        "            errD_fake = BCEloss(scores_fake, label)\n",
        "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = scores_fake.mean().item()\n",
        "            # Compute error of D as sum over the fake and the real batches\n",
        "            errD = (errD_real + errD_fake)/2\n",
        "            # errD.backward()\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "\n",
        "\n",
        "            ############################\n",
        "            # (2) Update G network: maximize log(D(G(z)))\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)  # fake labels are real for generator cost\n",
        "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "            scores_fake = netD(real_past_traj, fake).view(-1)\n",
        "            # Calculate G's loss based on this output\n",
        "            errG = BCEloss(scores_fake, label) # + 10 * MSELoss(output, label)\n",
        "            \n",
        "            # Calculate gradients for G\n",
        "            errG.backward()\n",
        "            D_G_z2 = scores_fake.mean().item()\n",
        "            # Update G\n",
        "            optimizerG.step()\n",
        "\n",
        "            # Output training stats\n",
        "            if i % 50 == 0:\n",
        "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                    % (epoch, num_epochs, i, len(train_loader),\n",
        "                        errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "                # print(BCEloss(output, label), MSELoss(output, label))\n",
        "                \n",
        "\n",
        "            # Save Losses for plotting later\n",
        "            G_losses.append(errG.item())\n",
        "            D_losses.append(errD.item())\n",
        "\n",
        "            iters += 1\n",
        "    return G_losses, D_losses\n",
        "\n",
        "\n",
        "def Train2(generator, discriminator, mode=\"WGAN\"):\n",
        "    # Lists to keep track of progress\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    iters = 0\n",
        "\n",
        "    # Establish convention for real and fake labels during training\n",
        "    real_label = 1.\n",
        "    fake_label = 0.\n",
        "\n",
        "    # Initialize BCELoss and MSELoss function\n",
        "    # BCEloss = nn.BCELoss()\n",
        "    MSELoss = nn.MSELoss()\n",
        "\n",
        "    # Training Loop\n",
        "    print(\"Starting Training Loop...\")\n",
        "    # For each epoch\n",
        "    for epoch in range(num_epochs):\n",
        "        # For each batch in the dataloader\n",
        "        for i, (real_past_traj, real_future_traj) in enumerate(train_loader):\n",
        "\n",
        "            ############################\n",
        "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "            ###########################\n",
        "\n",
        "            if mode == \"WGAN\":\n",
        "                n_critics_ = n_critics\n",
        "            else:\n",
        "                n_critics_ = 1\n",
        "\n",
        "            for _ in range(n_critics_):\n",
        "                ## Train with all-real batch\n",
        "                \n",
        "                # Format batch\n",
        "                real_past_traj = real_past_traj.to(device)\n",
        "                real_future_traj = real_future_traj.to(device)\n",
        "\n",
        "\n",
        "                # Forward pass real batch through D\n",
        "                scores_real = netD(real_past_traj, real_future_traj).view(-1)\n",
        "                D_x = scores_real.mean().item()\n",
        "\n",
        "                ## Train with all-fake batch\n",
        "                # Generate batch of latent vectors\n",
        "                noise = torch.randn((real_past_traj.size(0),1,36,10), device=device)\n",
        "                # Generate future traj batch with G\n",
        "                fake = netG(real_past_traj, noise)\n",
        "                # Classify all fake batch (generated future traj) with D\n",
        "                scores_fake = netD(real_past_traj, fake.detach()).view(-1)\n",
        "                D_G_z1 = scores_fake.mean().item()\n",
        "\n",
        "                # Compute error of D as sum over the fake and the real batches\n",
        "                # errD = d_loss(scores_real, scores_fake,mode)              # regular loss\n",
        "\n",
        "                gp = gradient_penalty(netD, real_past_traj, real_future_traj, fake, device=device)            # Gradient Penalty\n",
        "                errD = (-(torch.mean(scores_real) - torch.mean(scores_fake)) + Lambda_gp * gp)                # WGAN-GP loss\n",
        "                \n",
        "                \n",
        "                netD.zero_grad()\n",
        "                errD.backward(retain_graph=True)\n",
        "                # Update D\n",
        "                optimizerD.step()\n",
        "\n",
        "                # modification: clip param for discriminator\n",
        "                if mode==\"WGAN\":\n",
        "                    for parm in discriminator.parameters():\n",
        "                        parm.data.clamp_(-clamp_num, clamp_num)\n",
        "\n",
        "\n",
        "            ############################\n",
        "            # (2) Update G network\n",
        "            ###########################\n",
        "            netG.zero_grad()\n",
        "            # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "            scores_fake = netD(real_past_traj, fake).view(-1)\n",
        "            # Calculate G's loss based on this output\n",
        "            # errG = g_loss(scores_fake, fake, real_future_traj ).    # Regular BCE loss\n",
        "            errG = - torch.mean(scores_fake) + 1000 * MSELoss(fake, real_future_traj)                       # WGAN loss\n",
        "            # Calculate gradients for G\n",
        "            errG.backward()\n",
        "            D_G_z2 = scores_fake.mean().item()\n",
        "            # Update G\n",
        "            optimizerG.step()\n",
        "\n",
        "            # Output training stats\n",
        "            if i % 50 == 0:\n",
        "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                    % (epoch, num_epochs, i, len(train_loader),\n",
        "                        errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "                \n",
        "\n",
        "            # Save Losses for plotting later\n",
        "            G_losses.append(errG.item())\n",
        "            D_losses.append(errD.item())\n",
        "\n",
        "            iters += 1\n",
        "    return G_losses, D_losses\n"
      ],
      "metadata": {
        "id": "X3-lLzHEdWYS"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function mode\n",
        "mode = \"WGAN\"\n",
        "clamp_num = 0.1\n",
        "n_critics = 1\n",
        "Lambda_gp = 10\n",
        "\n",
        "# Optimizer algorithm \"sgd\" or \"rmsp\" or \"adam\"\n",
        "opt = \"adam\"\n",
        "# Number of training epochs\n",
        "num_epochs = 5\n",
        "# Learning rate for optimizers\n",
        "D_lr = 0.00005\n",
        "G_lr = 0.00005\n",
        "# Beta1 hyperparam for Adam optimizers\n",
        "beta1 = 0.5\n",
        "# Discrimiator network size\n",
        "D_start_filter_number = 2\n",
        "D_fc_layer_out_size = 4\n",
        "# Generator network size\n",
        "G_start_filter_num = 4\n",
        "\n",
        "\n",
        "embedding_size,input_length = 32, 10\n",
        "\n",
        "\n",
        "## Define Discriminator\n",
        "netD = DiscriminatorModel(D_start_filter_number, D_fc_layer_out_size).to(device)\n",
        "netD.train()\n",
        "netD.apply(weights_init)\n",
        "D_total_params = sum(p.numel() for p in netD.parameters())\n",
        "print(\"D number of parameters: \", D_total_params)\n",
        "# print(netD)\n",
        "\n",
        "## Define Generator\n",
        "netG = GeneratorModel(G_start_filter_num).to(device)\n",
        "netG.train()\n",
        "netG.apply(weights_init)\n",
        "G_total_params = sum(p.numel() for p in netG.parameters())\n",
        "print(\"G number of parameters: \", G_total_params)\n",
        "# print(netG)\n",
        "\n",
        "\n",
        "## Setup Adam optimizers for both G and D\n",
        "optimizerD, optimizerG = optimizer(opt)\n",
        "\n",
        "\n",
        "## Train\n",
        "G_loss, D_loss = Train2(generator, discriminator, mode=mode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1BbVMJBmwy9",
        "outputId": "fe0c1abc-1053-4447-89ff-387fc0e7220f"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D number of parameters:  71781\n",
            "G number of parameters:  66578\n",
            "Starting Training Loop...\n",
            "[0/5][0/340]\tLoss_D: 6.9198\tLoss_G: 47.6988\tD(x): 0.0511\tD(G(z)): 0.0498 / 0.0500\n",
            "[0/5][50/340]\tLoss_D: 0.4287\tLoss_G: 25.0319\tD(x): 0.0631\tD(G(z)): 0.0522 / 0.0517\n",
            "[0/5][100/340]\tLoss_D: 0.1504\tLoss_G: 16.0655\tD(x): 0.0711\tD(G(z)): 0.0539 / 0.0537\n",
            "[0/5][150/340]\tLoss_D: 0.0865\tLoss_G: 15.5730\tD(x): 0.0607\tD(G(z)): 0.0412 / 0.0407\n",
            "[0/5][200/340]\tLoss_D: 0.0590\tLoss_G: 15.0075\tD(x): 0.0708\tD(G(z)): 0.0565 / 0.0563\n",
            "[0/5][250/340]\tLoss_D: 0.0337\tLoss_G: 12.1386\tD(x): 0.0675\tD(G(z)): 0.0535 / 0.0532\n",
            "[0/5][300/340]\tLoss_D: 0.0026\tLoss_G: 12.1439\tD(x): 0.0570\tD(G(z)): 0.0207 / 0.0199\n",
            "[1/5][0/340]\tLoss_D: 0.0247\tLoss_G: 11.7725\tD(x): 0.0490\tD(G(z)): 0.0052 / 0.0029\n",
            "[1/5][50/340]\tLoss_D: -0.0301\tLoss_G: 10.3664\tD(x): 0.0382\tD(G(z)): -0.0279 / -0.0288\n",
            "[1/5][100/340]\tLoss_D: -0.0277\tLoss_G: 8.7420\tD(x): 0.0066\tD(G(z)): -0.0651 / -0.0647\n",
            "[1/5][150/340]\tLoss_D: -0.0888\tLoss_G: 10.1396\tD(x): -0.0213\tD(G(z)): -0.1437 / -0.1467\n",
            "[1/5][200/340]\tLoss_D: -0.1595\tLoss_G: 9.4107\tD(x): -0.0279\tD(G(z)): -0.2222 / -0.2277\n",
            "[1/5][250/340]\tLoss_D: -0.2976\tLoss_G: 9.8599\tD(x): -0.0109\tD(G(z)): -0.3420 / -0.3488\n",
            "[1/5][300/340]\tLoss_D: -0.3471\tLoss_G: 8.3202\tD(x): -0.0296\tD(G(z)): -0.4911 / -0.4892\n",
            "[2/5][0/340]\tLoss_D: -0.5300\tLoss_G: 9.7362\tD(x): 0.0092\tD(G(z)): -0.6053 / -0.5883\n",
            "[2/5][50/340]\tLoss_D: -0.6081\tLoss_G: 8.5738\tD(x): 0.0463\tD(G(z)): -0.6879 / -0.6815\n",
            "[2/5][100/340]\tLoss_D: -0.8022\tLoss_G: 9.8666\tD(x): 0.0903\tD(G(z)): -0.8569 / -0.8380\n",
            "[2/5][150/340]\tLoss_D: -0.8381\tLoss_G: 9.4210\tD(x): 0.1365\tD(G(z)): -0.8132 / -0.8775\n",
            "[2/5][200/340]\tLoss_D: -0.9095\tLoss_G: 8.6366\tD(x): 0.0782\tD(G(z)): -0.9117 / -0.8833\n",
            "[2/5][250/340]\tLoss_D: -0.8918\tLoss_G: 8.3529\tD(x): 0.0726\tD(G(z)): -0.8936 / -0.8803\n",
            "[2/5][300/340]\tLoss_D: -0.9054\tLoss_G: 8.8885\tD(x): 0.0478\tD(G(z)): -0.9346 / -0.9401\n",
            "[3/5][0/340]\tLoss_D: -0.8533\tLoss_G: 8.3668\tD(x): -0.0735\tD(G(z)): -1.0152 / -1.0387\n",
            "[3/5][50/340]\tLoss_D: -1.1242\tLoss_G: 9.3474\tD(x): -0.0293\tD(G(z)): -1.2450 / -1.2037\n",
            "[3/5][100/340]\tLoss_D: -0.9881\tLoss_G: 8.3108\tD(x): 0.0008\tD(G(z)): -1.0861 / -1.0939\n",
            "[3/5][150/340]\tLoss_D: -0.9449\tLoss_G: 8.1518\tD(x): -0.0868\tD(G(z)): -1.1132 / -1.0962\n",
            "[3/5][200/340]\tLoss_D: -0.9406\tLoss_G: 7.4421\tD(x): -0.0066\tD(G(z)): -1.0112 / -1.0641\n",
            "[3/5][250/340]\tLoss_D: -0.9774\tLoss_G: 8.3364\tD(x): 0.0620\tD(G(z)): -0.9776 / -1.0952\n",
            "[3/5][300/340]\tLoss_D: -1.1265\tLoss_G: 8.6644\tD(x): -0.1051\tD(G(z)): -1.3197 / -1.3068\n",
            "[4/5][0/340]\tLoss_D: -0.9190\tLoss_G: 7.7145\tD(x): 0.0021\tD(G(z)): -1.0767 / -1.1016\n",
            "[4/5][50/340]\tLoss_D: -1.2072\tLoss_G: 8.9827\tD(x): -0.0136\tD(G(z)): -1.3052 / -1.2787\n",
            "[4/5][100/340]\tLoss_D: -1.1227\tLoss_G: 9.7936\tD(x): -0.0098\tD(G(z)): -1.2271 / -1.2641\n",
            "[4/5][150/340]\tLoss_D: -1.0098\tLoss_G: 7.4972\tD(x): -0.0968\tD(G(z)): -1.1688 / -1.1951\n",
            "[4/5][200/340]\tLoss_D: -0.9564\tLoss_G: 7.6045\tD(x): -0.1203\tD(G(z)): -1.1451 / -1.1882\n",
            "[4/5][250/340]\tLoss_D: -0.9656\tLoss_G: 7.9627\tD(x): -0.1770\tD(G(z)): -1.2141 / -1.2497\n",
            "[4/5][300/340]\tLoss_D: -0.9077\tLoss_G: 7.4712\tD(x): -0.1984\tD(G(z)): -1.1882 / -1.1979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_loss,label=\"G\")\n",
        "plt.plot(D_loss,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "e0sQccQ0KcJF",
        "outputId": "799e795f-513f-48a1-fb50-f4a3e703c05c"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "netG.eval()\n",
        "for i, (real_past_traj, real_future_traj) in enumerate(train_loader):\n",
        "    # Format batch\n",
        "    real_past_traj = real_past_traj.to(device)\n",
        "    real_future_traj = real_future_traj.to(device)\n",
        "\n",
        "    # Generate batch of latent vectors\n",
        "    noise = torch.randn((real_past_traj.size(0),1,36,10), device=device)\n",
        "    # Generate future traj batch with G\n",
        "    fake = netG(real_past_traj, noise)\n",
        "    break"
      ],
      "metadata": {
        "id": "dkuaAlco0sg4"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_past_traj = real_past_traj.to(device)\n",
        "real_future_traj = real_future_traj.to(device)\n",
        "\n",
        "# Generate batch of latent vectors\n",
        "noise = torch.randn((real_past_traj.size(0),1,36,10), device=device)\n",
        "# Generate future traj batch with G\n",
        "fake = netG(real_past_traj, noise)\n",
        "for i in range(1):\n",
        "    plt.scatter(real_past_traj[i,0,0].to(\"cpu\").numpy(), real_past_traj[i,1,0].to(\"cpu\").numpy())\n",
        "    plt.scatter(real_future_traj[i,0,0].to(\"cpu\").numpy(), real_future_traj[i,1,0].to(\"cpu\").numpy())\n",
        "    plt.scatter(fake[i,0,0].detach().to(\"cpu\").numpy(), fake[i,1,0].detach().to(\"cpu\").numpy())\n",
        "MSELoss = nn.MSELoss()\n",
        "print(MSELoss(fake[i,:,:], real_future_traj[i,:,:]))\n",
        "print(fake[i,:,0], real_future_traj[i,:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sEZySrf9hcMB",
        "outputId": "96a1c8e3-2dd5-4393-dd92-9dce1c1ce4eb"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor([[ 0.3011,  0.2931,  0.2993,  0.3044,  0.3030,  0.2990,  0.2871,  0.2838,\n",
            "          0.2890,  0.2924],\n",
            "        [-0.3151, -0.3096, -0.3188, -0.3333, -0.3448, -0.3379, -0.3193, -0.2929,\n",
            "         -0.3272, -0.3392]], device='cuda:0', grad_fn=<SelectBackward0>) tensor([[ 0.4075,  0.4060,  0.4040,  0.4017,  0.3990,  0.3960,  0.3928,  0.3894,\n",
            "          0.3859,  0.3823],\n",
            "        [-0.4580, -0.4562, -0.4539, -0.4511, -0.4478, -0.4442, -0.4401, -0.4358,\n",
            "         -0.4310, -0.4259]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PMUyytWu70zI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}